{
    "project": "YaCUP-Music",
    "name": "embeddings dropout",
    "n_gpu": 1,

    "arch": {
        "type": "TransformerDecoder",
        "args": {
            "d_model": 768,
            "nhead": 4,
            "num_layers": 2,
            "dropout": 0.1,
            "n_classes": 256,
            "dim_feedforward": 2048 
        }
    },
    "dataset": {
        "type": "DataModule",
        "args": {
            "shuffle": true,
            "workers": 8,
            "seed": 42,
            "test_size": 0.2,
            "batch_size": 64,
            "labels_path": "dataset/train.csv",
            "dataset_args": {
                "embed_path": "dataset/embeddings/",
                "rt_load": true,
                "augment_enable": true,
                "cat_p": 0,
                "n_cat": 0,
                "delete_p": 0.8,
                "f_deletes": 0.2,
                "dropout_p": 0.8,
                "f_dropout": 0.2
            }
        }        
    },
    "optimizer": {
        "type": "Adam",
        "args":{
            "lr": 3e-4,
            "weight_decay": 1e-4,
            "amsgrad": false
        }
    },
    "loss": {
        "type": "AsymmetricLoss",
        "args": {
            "gamma_neg": 1,
            "gamma_pos": 1        
        }
    },
    "metrics": [
        "accuracy", "top_k_acc"
    ],
    "lr_scheduler": {
        "type": "StepLR",
        "args": {
            "step_size": 40,
            "gamma": 0.1
        }
    },
    "trainer": {
        "epochs": 200,

        "save_dir": "saved/",
        "save_period": 1,
        "verbosity": 2,
        
        "monitor": "max val/AP",
        "early_stop": 1000,

        "tensorboard": true
    }
}
